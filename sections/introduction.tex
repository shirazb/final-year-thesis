\section{Introduction}
Machine learning (ML) has become wildly popular among scientists, engineers, and even in the mainstream media, due to the unprecedented results it repeatedly provides in a multitude of areas. To name a few, we now have voice-controlled personal assistants; self-driving cars; computers that can beat the best human players at complex games like StarCraft; suggested replies on messaging apps; many advances in computer vision such as automatic captioning; automatic fraud detection in finance; and automatic lesion detection in the fight against cancer. [REFS] \\

Artificial Neural Networks (ANNs), or Deep Learning, is the key technique behind many of these advances. They are a form of supervised statistical model. That is, given a set of \(\{x \in \R^n, \ y \in \R^m\}\) labelled data points (e.g. the pixels of an image and the classification of the image), they try to learn the underlying function from input \(x\) to output \(y\). ANNs use a particular kind of function representation made from the composition of elementary functions, or neurons, and try to incrementally optimise the parameters of the functions by comparing the output of the network against the training data. The optimisation technique applied is almost always some variant of gradient descent, and the algorithm for applying it to an ANN is known as \textit{backpropagation}. An example neural network is given in [FIGURE]. A high-level overview of backpropagation is given in [FIGURE]. \\

As most of the neurons are performing tensor operations like multiplication to large batches of independent [FTNT: computationally not probabilistically] data points, Deep Learning can be massively sped up by exploiting the parallelism of GPUs [?]. However, state-of-the-art models have far surpassed the memory available on even top-tier GPUs [?], and continue to get larger [?]. \\

We can see how the large memory requirement arises by examining the computational graph, or data-flow graph, of backpropagation given in [FIGURE]. As can be seen, the forward tensors cannot be done in-place and must be kept around for the backward pass. f and b can only be freed once b has been computed, resulting in a peak memory requirement of [EQN], which is [ORDER N]. \\

All the non-software-level solutions to this problem, such as distributing the workload or using custom processors like TPUs, are highly expensive, highly complex, and far from fully worked out. Thus, finding a solution that can be cheaply implemented in existing ML software and is transparent to the user is highly desirable (as well as orthogonal to the other approaches). \\

Many such approaches exist, but all have their drawbacks. For example, quantization decreases the model's accuracy [?]; and GPU-CPU data swapping may require expert human intervention, is difficult to tractably solve for the optimal swapping strategy, and is hard to implement as you must delve deep into the ML framework's memory manager and have it precisely pipeline data transfer, memory allocation/deallocation, and computation [?]. \\

In this thesis, we focus on a technique known as checkpointing, which results in large memory savings, is much simpler to implement, does not affect model accuracy and requires minimal effort from the user; though it is hard to solve tractably and, compared to a theoretically optimal swapping implementation, the compute overhead may be poor, though still very acceptable. \\

Checkpointing trades computation for memory by only storing, or \textit{checkpointing}, some of the intermediate forwards and recomputing them later when required in the backwards pass. This causes backpropagation to become segmented, as shown in [FIGURE]. Chen [?] derives that, for \(k\) segments this achieves a sublinear peak memory cost of [EQN]. The same paper also proposes recursively applying this technique to the segments to further trade compute for memory: during the recomputation of a segment, only checkpoint some tensors and recompute the rest in the backward, thus resulting in `multiple recomputations'. \\

The question now becomes of solving for the optimal checkpointing policy: which tensors to checkpoint, how many to checkpoint, and how best to exploit multiple recomputations, such as to satisfy the memory budget with the least computational cost? The solution depends on the precise memory budget and per-layer compute and memory costs. DeepMind solve this for Recurrent Neural Networks (RNNs) using dynamic programming [?]. However, RNNs comprise a sequence of solely the same layer repeated many times, giving uniform per-layer compute and memory costs - a very simplifying assumption that does not at all hold for the majority of neural networks. \\

Furthermore, popular ML frameworks like TensorFlow [?], MxNet [?], and PyTorch [?] have very limited support for checkpointing. PyTorch, MxNet, and a third-party TensorFlow library by OpenAI [?] have similar functionality. They force the user to specify the number of segments and will split the sequence evenly, or asks the user to choose the checkpoints. They do not support multiple recomputations. TensorFlow's internal graph optimizer Grappler employs a non-optimal, user-guided, greedy, heuristic-based approach that finds the backward nodes in the computational graph, selects their inputs and the user-specified inputs as candidates for dropping, then does so until the memory budget is satisfied. Moreover, Grappler, in our opinion, requires non-trivial effort on the user's behalf to manually configure. \\

Therefore, to improve upon the above discussed limitations of checkpointing, we make the following contributions in this thesis:
\begin{itemize}
    \item We extend the existing dynamic programming technique proposed by DeepMind [?] to solve for the optimal checkpointing policy of a feedforward neural network given arbitrary per-layer compute and memory costs and the memory budget.
    \item We provide an implementation of this technique in PyTorch that should easily allow the user to overcome out-of-memory errors. Given only the user's existing sequential network, it will
    \begin{enumerate}
        \item Profile the precise per-layer costs,
        \item Solve for the optimal checkpointing policy,
        \item Present a helper function that can be called in the user's training loop to execute the sequence according to the policy, satisying the memory budget.
    \end{enumerate}
\end{itemize}
